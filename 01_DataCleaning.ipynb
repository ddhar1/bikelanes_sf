{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning of Bike Lane Data\n",
    "\n",
    "San Francisco has a bike system but some argue that there are improvements to be made. Many streets do not have bike lanes, and the bike lanes that do exist do not have lane dividers and or cars allowd to be parked in the lane. \n",
    "\n",
    "Opponents of bike lanes say that they do not have an affect on accident outcomes and can away parking spaces that would allow customers to park near businesses.\n",
    "\n",
    "I would like to study the bike lanes in SF using data from [DataSF](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-Historical-2003/tmnf-yvry). After using [lane-breach](https://github.com/lanebreach)'s API to match traffic accident data to bike lanes in SF, I would like visualize the accident data, as well as run a regression to attempt to quantify the impact of bike lanes on accidents\n",
    "\n",
    "\n",
    "[Vision Zero SF](https://sfgov.org/scorecards/transportation/traffic-fatalities) apparently tried to do a study, but\n",
    "I start with a dataframe of traffic accident police reports. Then I:\n",
    "    1. Map Accidents to bike lanes using lane breach's API to map accidents to bike lanes\n",
    "    2. Read Road map of SF, and merge this road map to the traffic accident/bike lane dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c61787c52190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import Axes\n",
    "from shapely.geometry import Point, shape\n",
    "import requests\n",
    "from itertools import compress\n",
    "from plotnine import *\n",
    "\n",
    "#!/usr/bin/python\n",
    "import psycopg2\n",
    "import pgdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accident Data\n",
    "\n",
    "We are looking at Accident data pulled from DataSF from the years 2003 through 2018. All these accidents are just general bike lane accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull in police report data\n",
    "reports_03_18 = pd.read_csv('CodeforSF/Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv', engine='python')\n",
    "reports_03_18[( reports_03_18['Descript'].str.contains(\"^TRAFFIC\") )  & ( reports_03_18['Descript'].str.contains(\"^TRAFFIC VIOLATION\") == False )]\n",
    "\n",
    "# filter by reports which contain the word traffic, sans traffic violations\n",
    "traffic_reports = reports_03_18[( reports_03_18['Descript'].str.contains(\"^TRAFFIC\") )  & ( reports_03_18['Descript'].str.contains(\"^TRAFFIC VIOLATION\") == False )]\n",
    "\n",
    "\n",
    "#traffic_reports_orig_index = reports_03_18[ reports_03_18['Descript'] == \"TRAFFIC ACCIDENT\" ]\n",
    "\n",
    "\n",
    "#reports_03_18[ reports_03_18['Descript'] == \"TRAFFIC ACCIDENT\" ]\n",
    "traffic_reports = traffic_reports.reset_index(drop = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at unique values to figure out what can we analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_values(df):\n",
    "    id = []\n",
    "    for i in df:\n",
    "        try: \n",
    "            length_of_column = len(np.unique(df[i]))\n",
    "            if ( length_of_column > (df.shape[0]*.01)): # if greater than a 1/6 of the dataset shape, don't even bother printing them \n",
    "                id.append( i )\n",
    "            elif length_of_column < (df.shape[0]*.01):\n",
    "                print(i, df[i].value_counts(),\"\\n\" )\n",
    "        except: next\n",
    "    print( \"a lot of unique values in these columns: \", id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category NON-CRIMINAL      1238\n",
      "OTHER OFFENSES     916\n",
      "Name: Category, dtype: int64 \n",
      "\n",
      "Descript TRAFFIC ACCIDENT                                 1238\n",
      "TRAFFIC COLLISION, HIT & RUN, PROPERTY DAMAGE     616\n",
      "TRAFFIC COLLISION, HIT & RUN, INJURY              300\n",
      "Name: Descript, dtype: int64 \n",
      "\n",
      "DayOfWeek Friday       330\n",
      "Saturday     317\n",
      "Wednesday    316\n",
      "Monday       315\n",
      "Thursday     305\n",
      "Tuesday      288\n",
      "Sunday       283\n",
      "Name: DayOfWeek, dtype: int64 \n",
      "\n",
      "PdDistrict MISSION       307\n",
      "SOUTHERN      296\n",
      "BAYVIEW       286\n",
      "INGLESIDE     277\n",
      "TARAVAL       253\n",
      "NORTHERN      215\n",
      "CENTRAL       166\n",
      "RICHMOND      157\n",
      "PARK          122\n",
      "TENDERLOIN     75\n",
      "Name: PdDistrict, dtype: int64 \n",
      "\n",
      "Resolution NONE                                      1040\n",
      "ARREST, BOOKED                             893\n",
      "ARREST, CITED                              150\n",
      "JUVENILE BOOKED                             15\n",
      "UNFOUNDED                                   13\n",
      "EXCEPTIONAL CLEARANCE                       11\n",
      "COMPLAINANT REFUSES TO PROSECUTE             9\n",
      "JUVENILE CITED                               7\n",
      "NOT PROSECUTED                               6\n",
      "DISTRICT ATTORNEY REFUSES TO PROSECUTE       6\n",
      "PSYCHOPATHIC CASE                            2\n",
      "JUVENILE ADMONISHED                          1\n",
      "LOCATED                                      1\n",
      "Name: Resolution, dtype: int64 \n",
      "\n",
      "a lot of unique values in these columns:  ['IncidntNum', 'Date', 'Time', 'Address', 'X', 'Y', 'Location', 'PdId']\n"
     ]
    }
   ],
   "source": [
    "unique_values(traffic_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just from eyeballing the sample sizes, given that I will at least be having 15 years of data with bike lanes, I wouldn't trust estimates of coefficients for variables tellings us whether or not there's a bike lane buffer, whether or not there's a bike lane barrier, and whether or not there's a greenwave (light on ground). No bikelanes are in the opposite direction of the bike route. \n",
    "\n",
    "At the very least, it would be interesting to do analysis for sharrows and for bike routes/lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Accidents to bike lanes using lane breach's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using lane breach's API to to map coordinates of bike lanes to actual accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"https://lane-breach.herokuapp.com/api/bikeway_networks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distance is in meters to the bike lane \n",
    "# returns a string that is firstly a array with _\n",
    "# if there is no bike lane, it may be better to just skip it because it would save us subsetting and the work of appending.\n",
    "def accident_near_bikelane( Y, X ):\n",
    "    output =[0, '', 'nolane', 0 ]\n",
    "    PARAMS = {'lat': Y, 'long': X}\n",
    "    r = requests.get(url = URL, params = PARAMS)\n",
    "    save = r.text\n",
    "    if r.text == 'null':\n",
    "        return([])\n",
    "    else:\n",
    "        return(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikelane_x = traffic_reports['X'].reset_index( drop = True)\n",
    "bikelane_y = traffic_reports['Y'].reset_index( drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "## START HERE\n",
    "bikelane_exist = []\n",
    "bikelane_info = []\n",
    "\n",
    "#for i in range(0, accident_data.shape[0]):\n",
    "for i in range(0, len(bikelane_x)):\n",
    "    accident_bike_info = accident_near_bikelane( bikelane_y[i], bikelane_x[i])\n",
    "    \n",
    "    bikelane_info.append(accident_bike_info)\n",
    "\n",
    "    if len(accident_bike_info) == 0:\n",
    "        bikelane_exist.append(False)\n",
    "    else:\n",
    "        bikelane_exist.append(True)\n",
    "#print(bikelane_exist) # use this to subset\n",
    "#print(bikelane_info)\n",
    "\n",
    "#%slack traffic report mapping to bike lane code has finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeobjectid( save ):\n",
    "    # parse out the objectid from output\n",
    "    try:\n",
    "        #output = float(save[ (save.find(\"objectid\\\"\", 0, len(save)) +10):( save.find(\"qtr\", 0, len(save))-2) ])\n",
    "        #output = float(save[ (save.find(\"cnn\\\"\", 0, len(save)) +5):( save.find(\"contra\", 0, len(save))-2) ])\n",
    "        output = save[ (save.find(\"globalid\\\"\", 0, len(save)) +11):( save.find(\"greenwave\", 0, len(save))-3) ]\n",
    "    except:\n",
    "        output = \"\"\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikelane_objectid = pd.DataFrame({'globalid': np.array(bikelane_info)})\n",
    "bikelane_objectid['globalid'] = bikelane_objectid['globalid'].apply( lambda x: removeobjectid(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def removeinstallyr( save ):\n",
    "    # parse out the objectid from output\n",
    "    try:\n",
    "        output = int(save[ (save.find(\"install_yr\\\"\", 0, len(save)) +12):( save.find(\"last_edite\", 0, len(save))-2) ])\n",
    "    except:\n",
    "        output = int(0)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikelane_installyr = pd.DataFrame({'install_yr': np.array(bikelane_info)})\n",
    "bikelane_installyr['install_yr'] = bikelane_installyr['install_yr'].apply( lambda x: removeinstallyr(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#traffic_reports.columns, bikelane_info2.columns, bikelane_exist2.columns, traffic_reports_bikelaneobjectids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikelane_exist2= pd.DataFrame( {'bikelane_exist': np.array(bikelane_exist)} )\n",
    "\n",
    "# merge bike lane info to the traffic accidents by\n",
    "traffic_reports_bikelaneobjectids = pd.concat([traffic_reports, bikelane_objectid, bikelane_exist2, bikelane_installyr ], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date of accident to datetime object. Compare bike lane installation date to it\n",
    "traffic_reports_bikelaneobjectids['Date'] = pd.to_datetime(traffic_reports['Date'])\n",
    "traffic_reports_bikelaneobjectids['accident_year'] = traffic_reports['Date'].apply( lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final list of traffic accidents mapped to bike lanes object id. Out of ~2000, ~900 had accidents. Due to time it takes for the data frame to load, the traffic bike lane dataset was written to file, and I'm uploading it here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv since that script is a pain\n",
    "traffic_reports_bikelaneobjectids.to_csv('BikewayNetwork_edit/traffic_reports_bikelaneobjectid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_bikelaneobjectids = pd.read_csv('BikewayNetwork_edit/traffic_reports_bikelaneobjectid.csv')\n",
    "traffic_reports_bikelaneobjectids = traffic_reports_bikelaneobjectids.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_bikelaneobjectids['Date'] = pd.to_datetime(traffic_reports_bikelaneobjectids['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's join the traffic dataset to the bike lane dataframe in order to figure out what was made first and then second.\n",
    "\n",
    "More information about the bike lane dataset can be found [here](https://data.sfgov.org/Transportation/SFMTA-Bikeway-Network/ygmz-vaxd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikeway_map3 = gpd.read_file('BikewayNetwork_edit/bikeway_map_wcensus.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biap NO     5155\n",
      "No       14\n",
      "YES       6\n",
      "Name: biap, dtype: int64 \n",
      "\n",
      "buffered NO     4929\n",
      "YES     246\n",
      "Name: buffered, dtype: int64 \n",
      "\n",
      "contraflow NO     5160\n",
      "No       10\n",
      "YES       5\n",
      "Name: contraflow, dtype: int64 \n",
      "\n",
      "direct 2W    4966\n",
      "1W     209\n",
      "Name: direct, dtype: int64 \n",
      "\n",
      "double 0.0    2705\n",
      "1.0    2450\n",
      "Name: double, dtype: int64 \n",
      "\n",
      "facility_t CLASS III    2808\n",
      "CLASS II     1857\n",
      "CLASS I       311\n",
      "CLASS IV      199\n",
      "Name: facility_t, dtype: int64 \n",
      "\n",
      "greenwave NO     5115\n",
      "YES      48\n",
      "No       12\n",
      "Name: greenwave, dtype: int64 \n",
      "\n",
      "date_last_ 2017-10-18    4595\n",
      "2017-12-27     244\n",
      "2017-12-11      70\n",
      "2018-01-17      50\n",
      "2017-12-28      42\n",
      "2018-01-09      39\n",
      "2018-07-20      27\n",
      "2018-03-19      25\n",
      "2018-05-08      16\n",
      "2017-10-25      16\n",
      "2018-08-14      13\n",
      "2017-12-21      12\n",
      "2018-07-13       7\n",
      "2018-04-18       6\n",
      "2018-08-13       5\n",
      "2018-04-25       4\n",
      "2018-05-25       2\n",
      "2018-06-22       1\n",
      "2018-04-24       1\n",
      "Name: date_last_, dtype: int64 \n",
      "\n",
      "last_edite JENWONG    5175\n",
      "Name: last_edite, dtype: int64 \n",
      "\n",
      "raised NO     5157\n",
      "YES      18\n",
      "Name: raised, dtype: int64 \n",
      "\n",
      "sharrow 0.0    3005\n",
      "1.0    2137\n",
      "2.0      14\n",
      "4.0       8\n",
      "3.0       8\n",
      "5.0       3\n",
      "Name: sharrow, dtype: int64 \n",
      "\n",
      "sm_sweeper NO     5091\n",
      "YES      84\n",
      "Name: sm_sweeper, dtype: int64 \n",
      "\n",
      "symbology BIKE ROUTE           2775\n",
      "BIKE LANE            1854\n",
      "BIKE PATH             311\n",
      "SEPARATED BIKEWAY     195\n",
      "NEIGHBORWAY            40\n",
      "Name: symbology, dtype: int64 \n",
      "\n",
      "a lot of unique values in these columns:  ['cnn', 'fy', 'globalid', 'install_mo', 'install_yr', 'time_last_', 'length', 'objectid', 'qtr', 'shape_len', 'update_mo', 'update_yr', 'censusbloc']\n"
     ]
    }
   ],
   "source": [
    "unique_values(bikeway_map3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikeway_map3['streetname'] = bikeway_map3['streetname'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes = traffic_reports_bikelaneobjectids.merge( bikeway_map3, how= 'left', \\\n",
    "                                                                                 on = 'globalid', indicator = True, suffixes=('_accid', '_bikelane'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_only     1191\n",
       "both           963\n",
       "right_only       0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports_and_bikelanes[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ~1200 traffic accidents that did not occur on or near a bike lane that existed in 2010. We should now figure out whether the accidents that occured near a bike lane in 2010 occured before or after the installation date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date of accident to datetime object. Compare bike lane installation date to it\n",
    "traffic_reports_and_bikelanes['Date'] = pd.to_datetime(traffic_reports_and_bikelanes['Date'])\n",
    "traffic_reports_and_bikelanes.loc[ traffic_reports_and_bikelanes['install_mo'].isnull(), 'install_mo'] = 1\n",
    "traffic_reports_and_bikelanes.loc[ traffic_reports_and_bikelanes['install_yr_bikelane'].isnull(), 'install_yr_bikelane'] = 3000 #the year when ppl live underwater\n",
    "traffic_reports_and_bikelanes['install_mo'] = traffic_reports_and_bikelanes['install_mo'].apply(int)\n",
    "traffic_reports_and_bikelanes['install_yr_bikelane'] = traffic_reports_and_bikelanes['install_yr_bikelane'].apply(int)\n",
    "traffic_reports_and_bikelanes['bikelane_installdate'] = traffic_reports_and_bikelanes['install_mo'].map(str) + '/01/' + traffic_reports_and_bikelanes['install_yr_bikelane'].map(str)\n",
    "traffic_reports_and_bikelanes['bikelane_installdate'] =  pd.to_datetime(traffic_reports_and_bikelanes['bikelane_installdate'], errors='coerce')\n",
    "traffic_reports_and_bikelanes['bikelane_exist'] = traffic_reports_and_bikelanes['bikelane_installdate'] < traffic_reports_and_bikelanes['Date']\n",
    "traffic_reports_and_bikelanes['accident_year'] = traffic_reports_and_bikelanes['Date'].apply( lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1379\n",
       "True      775\n",
       "Name: bikelane_exist, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports_and_bikelanes['bikelane_exist'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~1400 accidents that were not on an actual bike lane. 700 that were. A regression, especially one parsed by other arguements (such as year, neighborhood, day of week) would probably have issues with sample size. But I'll run one anyways after investigating the other variables for fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be useful to aggregate by weekday vs weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isWeekday( x ):\n",
    "    if x in ( 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday' ):\n",
    "        return('Weekday')\n",
    "    else: # assuming no errors in our dataset, oc\n",
    "        return('Weekend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes['isWeekday'] = traffic_reports_and_bikelanes.DayOfWeek.apply( lambda x: isWeekday( x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday    1554\n",
       "Weekend     600\n",
       "Name: isWeekday, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports_and_bikelanes.isWeekday.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accidents occur on a weekday! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if some of the bike lanes variables are relevant in understanding where accidents occur. The variables include bike lane barrier type, bike lane type, whether or not a buffer exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes_onlyexist = traffic_reports_and_bikelanes.loc[traffic_reports_and_bikelanes['bikelane_exist'] == True ].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO     738\n",
      "YES     37\n",
      "Name: buffered, dtype: int64 \n",
      "\n",
      "SAFE-HIT POSTS                       26\n",
      "PARKING; SAFE-HIT POSTS               8\n",
      "CONCRETE; PARKING; SAFE-HIT POSTS     7\n",
      "CONCRETE                              5\n",
      "PARKING                               4\n",
      "CONCRETE; SAFE-HIT POSTS              3\n",
      "K-RAIL                                2\n",
      "Name: barrier, dtype: int64 \n",
      "\n",
      "NO     741\n",
      "YES     34\n",
      "Name: greenwave, dtype: int64 \n",
      "\n",
      "0.0    486\n",
      "1.0    284\n",
      "5.0      2\n",
      "4.0      2\n",
      "2.0      1\n",
      "Name: sharrow, dtype: int64 \n",
      "\n",
      "NO    775\n",
      "Name: contraflow, dtype: int64 \n",
      "\n",
      "BIKE ROUTE           347\n",
      "BIKE LANE            337\n",
      "SEPARATED BIKEWAY     53\n",
      "BIKE PATH             38\n",
      "Name: symbology, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traffic_reports_and_bikelanes_onlyexist.loc[traffic_reports_and_bikelanes_onlyexist['bikelane_exist'] == True, 'buffered'].value_counts(), \"\\n\")\n",
    "print(traffic_reports_and_bikelanes_onlyexist.loc[traffic_reports_and_bikelanes_onlyexist['bikelane_exist'] == True, 'barrier'].value_counts(), \"\\n\")\n",
    "print(traffic_reports_and_bikelanes_onlyexist.loc[traffic_reports_and_bikelanes_onlyexist['bikelane_exist'] == True, 'greenwave'].value_counts(), \"\\n\")\n",
    "print(traffic_reports_and_bikelanes_onlyexist.loc[traffic_reports_and_bikelanes_onlyexist['bikelane_exist'] == True, 'sharrow'].value_counts(), \"\\n\")\n",
    "print(traffic_reports_and_bikelanes_onlyexist.loc[traffic_reports_and_bikelanes_onlyexist['bikelane_exist'] == True, 'contraflow'].value_counts(), \"\\n\")\n",
    "print(traffic_reports_and_bikelanes_onlyexist.loc[traffic_reports_and_bikelanes_onlyexist['bikelane_exist'] == True, 'symbology'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to guage if there are duplicates in this database. I know from SQL queries on mode that there can be 1-2 bike lanes on roads that are both one and two way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be interesting to look at accidents vs bike lane types, and if a sharrow exists since there seems to be a reasonable amount of accidents with sharrows, bike lanes. However, not enough of the other types (neighborways, contraflow routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road map of SF\n",
    "I'm now interested in figuring out how much of SF contains bike lanes? This will help us understand why so many accidents didn't match to a bike lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_map = gpd.read_file('Streets - Active and Retired/geo_export_ea4de75d-ee93-4ded-8f06-09caff29c4e1.shp')\n",
    "total_map = gpd.read_file(\"https://data.sfgov.org/resource/3psu-pn9h.geojson\")\n",
    "\n",
    "#total_map = pd.read_file(\"https://data.sfgov.org/resource/3psu-pn9h.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know from [here](https://data.sfgov.org/Geographic-Locations-and-Boundaries/Streets-Active-and-Retired/3psu-pn9h) that the column ' tells us which roads are available in 2018. \n",
    "\n",
    "We want to get the length of road since this dataset doesn't have a length of lane (unlike the bikeway map). We use the haversine formula since that can take coordinates and find the distance between them, accounting for the curvature of the earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "# Calculates distance between 2 GPS coordinates \n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3959 # Radius of earth in kilometers. Use 3959 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['barrier', 'biap', 'buffered', 'cnn', 'contraflow', 'date_creat',\n",
       "       'time_creat', 'created_us', 'dir', 'direct', 'double', 'facility_t',\n",
       "       'from_st', 'fy', 'globalid', 'greenwave', 'install_mo', 'install_yr',\n",
       "       'date_last_', 'time_last_', 'last_edite', 'length', 'notes', 'number',\n",
       "       'objectid', 'qtr', 'raised', 'shape_len', 'sharrow', 'sm_sweeper',\n",
       "       'street', 'streetname', 'surface_tr', 'symbology', 'to_st', 'update_mo',\n",
       "       'update_yr', 'censusbloc', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikeway_map3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So do we standardize our metric of accidents per length by area or by both sides of street? Let's get the lengths of each bike lane, the lengths of each road, and then join both to the list of accidents. we can then count the list of traffic accidents on bike lanes and on road maps through group bys? we could group by a neighborhood, and bike or road id vs road/bike lengths, and then sum the road or bike lengths and then count the accidents\n",
    "\n",
    "what about time? group by time, day, bike/road id vs length, and then sum road/bike lengths, and then count the accidents. I just want to verify that we should do all this at the accident level and I stand by that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate length of bike lanes\n",
    "bikelane_length = []\n",
    "\n",
    "for line in bikeway_map3.geometry:\n",
    "    numCoords = len(line.coords) - 1\n",
    "    distance = 0\n",
    "    for i in range(0, numCoords):\n",
    "        point1 = line.coords[i]\n",
    "        point2 = line.coords[i + 1]\n",
    "        distance += haversine(point1[0], point1[1], point2[0], point2[1])\n",
    "\n",
    "    bikelane_length.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bikeway_map3 = pd.concat( [bikeway_map3.reset_index(drop = True), pd.DataFrame( {'bikelane_length_haver': bikelane_length})], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate length of road in miles\n",
    "lengths_list = []\n",
    "\n",
    "for i in range(0, len(total_map.geometry)):\n",
    "    \n",
    "    current_path = total_map.loc[i, 'geometry']\n",
    "    \n",
    "    numCoords = len(current_path.coords) - 1\n",
    "    distance = 0\n",
    "    for i in range(0, numCoords):\n",
    "        point1 = current_path.coords[i]\n",
    "        point2 = current_path.coords[i + 1]\n",
    "        distance += haversine(point1[0], point1[1], point2[0], point2[1])\n",
    "        \n",
    "    # doubling the distance of 2 way bike lanes - accidents can happen at either side of the street\n",
    "    if total_map.loc[i, 'oneway'] == 'B':\n",
    "        distance *= 2\n",
    "\n",
    "    lengths_list.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_map = pd.concat( [pd.DataFrame({'road_length': lengths_list}), total_map], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.680000000000001 % of roads have bikelanes\n"
     ]
    }
   ],
   "source": [
    "print((round(np.sum(bikeway_map3.length) / np.sum(lengths_list),4)*100), \"%\", \"of roads have bikelanes. some of those roads may be inactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_map.nhood.value_counts() -> i would like higher level neighborhood groupings, but we can worry about that with the traffic accident police district dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False}\n",
      "{True}\n"
     ]
    }
   ],
   "source": [
    "#how to check whether date_drop means that all lanes are inacive\n",
    "print(set(total_map.loc[~total_map.date_dropped.isnull(), 'active']))\n",
    "print(set(total_map.loc[total_map.date_dropped.isnull(), 'active']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "total_map3 = total_map\n",
    "\n",
    "total_map3['date_dropped'] =  pd.to_datetime(total_map3.loc[~total_map3.date_dropped.isnull(), 'date_dropped']).apply( lambda x: pd.Timestamp(x))\n",
    "total_map3['date_added'] =  pd.to_datetime(total_map3.loc[~total_map3.date_dropped.isnull(), 'date_added']).apply( lambda x: pd.Timestamp(x))\n",
    "\n",
    "total_map3.loc[ total_map3.date_dropped.isnull(), 'date_added']  = pd.Timestamp(  dt.date(1900, 12, 31))\n",
    "total_map3.loc[ total_map3.date_dropped.isnull(), 'date_dropped']  = pd.Timestamp(  dt.date(2021, 12, 31))\n",
    "\n",
    "total_map3.geometry = gpd.GeoSeries(total_map3.geometry)\n",
    "total_map3.crs = bikeway_map3.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes.Date = traffic_reports_and_bikelanes.Date.apply(lambda x: pd.Timestamp( x ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes2 = traffic_reports_and_bikelanes.drop_duplicates(subset=['X', 'Y', 'IncidntNum'], keep = 'first').reset_index( drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes2['cnn_of_road'] = ['none']* traffic_reports_and_bikelanes2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(traffic_reports_and_bikelanes2.loc[i, 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns closest road to a road i. \n",
    "# i don't rellly care if i don't get the most accurate road at this point, just the min is fine even if it's first\n",
    "\n",
    "def geo_or_na( possible_geo ):\n",
    "    if np.isnan(possible_geo).all():\n",
    "        return None\n",
    "    else:\n",
    "        return traffic_reports_and_bikelanes2.loc[i, 'geometry'].distance(possible_geo)\n",
    "\n",
    "for i in range(0, len(traffic_reports_and_bikelanes2.geometry) ):\n",
    "    if np.isnan(traffic_reports_and_bikelanes2.loc[i, 'geometry']).all():\n",
    "        traffic_reports_and_bikelanes2.loc[i,'cnn_of_road'] = None\n",
    "        continue\n",
    "\n",
    "    total_map_for_testing =  total_map3.loc[ (traffic_reports_and_bikelanes2.loc[i,'Date'] >= total_map3.date_added) & (total_map3.date_dropped <= traffic_reports_and_bikelanes2.loc[i,'Date'])  ,   ]\n",
    "    distance_to_road = total_map_for_testing.geometry.apply( lambda x: geo_or_na(x) )\n",
    "    \n",
    "    if len(distance_to_road) == 0:\n",
    "        traffic_reports_and_bikelanes2.loc[i,'cnn_of_road']  = None\n",
    "    else:\n",
    "        # uses row index of road that has min distance to bike lane in question to return cnn of the road with min distance\n",
    "        traffic_reports_and_bikelanes2.loc[i,'cnn_of_road'] = total_map_for_testing.loc[distance_to_road.idxmin(), 'cnn'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge each lane with a bike lane\n",
    "\n",
    "traffic_reports_and_bikelanes3 = traffic_reports_and_bikelanes2.merge(total_map3, how = 'left', left_on ='cnn_of_road', right_on = 'cnn', suffixes=('_accid', '_road'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes3 = traffic_reports_and_bikelanes3.merge( bikeway_map3[['globalid', 'bikelane_length_haver']] , how = 'left', on = 'globalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_reports_and_bikelanes3['Time'] = pd.to_datetime(traffic_reports_and_bikelanes3['Time'])\n",
    "traffic_reports_and_bikelanes3['hour'] = traffic_reports_and_bikelanes3['Time'].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Data - Sample Sizes of Different Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bike lanes may or may not cause traffic accidents. In an ideal world where it's easy to understand the causal impact of something, the best way to analyze this would be to have two completely identical cities, that are basically the same except they're not, and randomly assign bike lanes to one and compare traffic accident numbers after a few weeks/years. That isn't possible.\n",
    "\n",
    "Another way is to look at how number of accidents increased or decrease per bike lane, for the year's after it's installed. Let's see if we have enough variability in a regression to do that. For each bike lane, are there accidents before it existed and after it existed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1379\n",
       "True      775\n",
       "Name: bikelane_exist, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports_and_bikelanes.bikelane_exist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_only     1191\n",
       "both           963\n",
       "right_only       0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports_and_bikelanes['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accidents don't have bike lanes associated with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = traffic_reports_and_bikelanes.groupby(['globalid', 'bikelane_exist']).count()['Date'].reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if a bike lane has both a before and after - if sum of both_true_false_check per globalid == 3, then they do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['both_true_false_check'] = traffic_reports_and_bikelanes.bikelane_exist.apply(lambda x: 1 if x == True else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test.groupby(['globalid']).sum()['both_true_false_check'] == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 19 bike lanes have accidents before and after! That is pretty disappointing and frankly wouldn't make a very good difference in difference at the bike lane level. I can run a regression of number of accidents on, and off a bike lane, for different neighorhoods per year, just to increase my sample size. \n",
    "\n",
    "But this regression would not be causal and I wouldn't get the results I want. I think it's better to investigate this problem through other means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are not that many counts per year, and we don't have many years of data! This is something to note when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_year  bikelane_exist\n",
       "2003           False              57\n",
       "               True               10\n",
       "2004           False              44\n",
       "               True                8\n",
       "2005           False              45\n",
       "               True               12\n",
       "2006           False              58\n",
       "               True               23\n",
       "2007           False              66\n",
       "               True               29\n",
       "2008           False              74\n",
       "               True               25\n",
       "2009           False              80\n",
       "               True               33\n",
       "2010           False              88\n",
       "               True               63\n",
       "2011           False              85\n",
       "               True               57\n",
       "2012           False             104\n",
       "               True               67\n",
       "2013           False              98\n",
       "               True               49\n",
       "2014           False             107\n",
       "               True               59\n",
       "2015           False              99\n",
       "               True               79\n",
       "2016           False             143\n",
       "               True              100\n",
       "2017           False             181\n",
       "               True              137\n",
       "2018           False              50\n",
       "               True               24\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports_and_bikelanes.groupby(['accident_year', 'bikelane_exist']).count()['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our options now are\n",
    "* Higher level investigation of results -> I really want to examine if accidents are correlated with not off road because of lack of bike lanes or if standardizing number of accidents by length will help\n",
    "* Visuals!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
